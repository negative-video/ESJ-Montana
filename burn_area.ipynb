{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burn Area Processing\n",
    "The purpose of this notebook is to find areas of Montana that have been burned by wildfires over time, and make informed decisions based on the findings.\n",
    "\n",
    "Though NASA offers a product called [FIRMS](https://firms.modaps.eosdis.nasa.gov) (Fire Information for Resource Managment System) which provides current and historic informations on active wildfires, you should not use this data to find land cover that has been burned.\n",
    "\n",
    "From the FIRMS [FAQ Page](https://www.earthdata.nasa.gov/faq/firms-faq):\n",
    "\n",
    "> It is not recommended to use active fire locations to estimate burned area due to spatial and temporal sampling issues. Determining this to an acceptable degree of accuracy is generally not possible due to nontrivial spatial and temporal sampling issues. For some applications, however, acceptable accuracy can be achieved, although the effective area burned per fire pixel is not simply a constant, but rather varies with respect to several different vegetation and fire-related variables. See [Giglio et al. (2006)](https://acp.copernicus.org/articles/6/957/2006/) for more information.\n",
    "\n",
    "Instead, we will use Dr. Giglio's [MODIS Burn Area Product](https://modis-fire.umd.edu/ba.html) to calculate wildfire damage. \n",
    "\n",
    "The product we are interested in is `MCD64 Burned Area Collection 6`. The user guide is located [here](https://modis-fire.umd.edu/files/MODIS_C6_BA_User_Guide_1.3.pdf), but the process will be walked through in this example. These products are hosted on an SFTP server hosted by the University of Maryland.\n",
    "\n",
    "### If you prefer an app-based SFTP client, follow these steps:\n",
    "\n",
    "* Open the SFTP program. Enter server address `fuoco.geog.umd.edu` , username `fire` , and password `burnt` . Log in.\n",
    "\n",
    "* Navigate the directory structure through `data` > `MODIS` > `C6` > `MCD64A1` > `SHP` .\n",
    "\n",
    "* Enter folder `Win03` , which represents the continental United States. Refer to the user guide if your area of interest resides elsewhere.\n",
    "\n",
    "* The resulting folder structure returns the years the product has produced. Make a folder within this project folder `ESJ-Montana` called `burnarea` and navigate to it in the opposite column of your SFTP client.\n",
    "\n",
    "* Drag-and-drop all relevant years into this `burnarea` folder. Wait for the download to complete.\n",
    "\n",
    "* Skip the next code block and do not run it, as it will just repeat the steps above.\n",
    "\n",
    "### If you wish to automatically download all relevant files, run the below cell block and enter your desired values when prompted:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available years: ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
      "Year 2000 has been downloaded.\n",
      "Year 2001 has been downloaded.\n",
      "Year 2002 has been downloaded.\n",
      "Year 2003 has been downloaded.\n",
      "Year 2004 has been downloaded.\n",
      "Year 2005 has been downloaded.\n",
      "Year 2006 has been downloaded.\n",
      "Year 2007 has been downloaded.\n",
      "Year 2008 has been downloaded.\n",
      "Year 2009 has been downloaded.\n",
      "Year 2010 has been downloaded.\n",
      "Year 2011 has been downloaded.\n",
      "Year 2012 has been downloaded.\n",
      "Year 2013 has been downloaded.\n",
      "Year 2014 has been downloaded.\n",
      "Year 2015 has been downloaded.\n",
      "Year 2016 has been downloaded.\n",
      "Year 2017 has been downloaded.\n",
      "Year 2018 has been downloaded.\n",
      "Year 2019 has been downloaded.\n",
      "Year 2020 has been downloaded.\n",
      "Files from 2000 to 2020 have been downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Only run this if you haven't manually downloaded burn area data!\n",
    "\n",
    "import pysftp\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "burn_area_folder = \"burnarea\"\n",
    "Path(burn_area_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# SFTP server details\n",
    "sftp_host = \"fuoco.geog.umd.edu\"\n",
    "username = \"fire\"\n",
    "password = \"burnt\"\n",
    "\n",
    "geog_region = \"Win03\" # Change this for a different geographical area: refer to user guide\n",
    "remote_directory = \"data/MODIS/C6/MCD64A1/SHP/\" + geog_region\n",
    "local_directory = burn_area_folder\n",
    "\n",
    "# Establish an SFTP connection and list year directories\n",
    "with pysftp.Connection(host=sftp_host, username=username, password=password) as sftp:\n",
    "    with sftp.cd(remote_directory):\n",
    "        all_directories = sftp.listdir()  # List all years\n",
    "\n",
    "# Filter for year directories\n",
    "year_directories = [dir for dir in all_directories if dir.isdigit() and 2000 <= int(dir) <= 9999]\n",
    "\n",
    "# Prompt for start and end year\n",
    "print(f\"Available years: {year_directories}\")\n",
    "start_year = int(input(\"Enter the beginning of the range to download: \"))\n",
    "end_year = int(input(\"Enter the end of the range to download: \"))\n",
    "\n",
    "# Validate user input\n",
    "if str(start_year) not in year_directories or str(end_year) not in year_directories or start_year > end_year:\n",
    "    print(\"Invalid year range selected.\")\n",
    "\n",
    "else:\n",
    "    # Establish another SFTP connection to download files\n",
    "    with pysftp.Connection(host=sftp_host, username=username, password=password) as sftp:\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            year_dir = os.path.join(remote_directory, str(year))\n",
    "            local_year_dir = os.path.join(local_directory, str(year))\n",
    "            \n",
    "            # Ensure local year directory exists\n",
    "            if not os.path.exists(local_year_dir):\n",
    "                os.makedirs(local_year_dir)\n",
    "            \n",
    "            with sftp.cd(year_dir): \n",
    "                files = sftp.listdir()\n",
    "                for file in files:\n",
    "                    sftp.get(file, os.path.join(local_year_dir, file))  # Download each file\n",
    "            \n",
    "            print(f\"Year {year} has been downloaded.\")\n",
    "\n",
    "    print(f\"Files from {start_year} to {end_year} have been downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of the burn area files have been downloaded, they need to be uncompressed before they can be interacted with. Run the below code to uncompress all files and delete the compressed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2000 has been extracted.\n",
      "Year 2001 has been extracted.\n",
      "Year 2002 has been extracted.\n",
      "Year 2003 has been extracted.\n",
      "Year 2004 has been extracted.\n",
      "Year 2005 has been extracted.\n",
      "Year 2006 has been extracted.\n",
      "Year 2007 has been extracted.\n",
      "Year 2008 has been extracted.\n",
      "Year 2009 has been extracted.\n",
      "Year 2010 has been extracted.\n",
      "Year 2011 has been extracted.\n",
      "Year 2012 has been extracted.\n",
      "Year 2013 has been extracted.\n",
      "Year 2014 has been extracted.\n",
      "Year 2015 has been extracted.\n",
      "Year 2016 has been extracted.\n",
      "Year 2017 has been extracted.\n",
      "Year 2018 has been extracted.\n",
      "Year 2019 has been extracted.\n",
      "Year 2020 has been extracted.\n",
      "All files extracted! Compressed files were deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Order the years ascending, and exclude any system files\n",
    "sorted_year_folders = sorted([folder for folder in os.listdir(burn_area_folder) if folder.isdigit()], key=int)\n",
    "\n",
    "# Iterate through each subfolder in the directory\n",
    "for year_folder in sorted_year_folders:\n",
    "    year_folder_path = os.path.join(burn_area_folder, year_folder)\n",
    "    \n",
    "    # Check if it's a directory and matches the year pattern (e.g., 2000, 2001, etc.)\n",
    "    if os.path.isdir(year_folder_path) and year_folder.isdigit():\n",
    "        # Iterate through each file in the year subfolder\n",
    "        for filename in os.listdir(year_folder_path):\n",
    "            file_path = os.path.join(year_folder_path, filename)\n",
    "            \n",
    "            # Check if the file is a .tar.gz file\n",
    "            if filename.endswith('.tar.gz'):\n",
    "                # Extract the .tar.gz file\n",
    "                with tarfile.open(file_path, 'r:gz') as tar:\n",
    "                    tar.extractall(path=year_folder_path)\n",
    "                \n",
    "                # Delete the .tar.gz file after extraction\n",
    "                os.remove(file_path)\n",
    "        print(f\"Year {year_folder} has been extracted.\")\n",
    "print(\"All files extracted! Compressed files were deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the files extracted, we are now ready to interact with them.\n",
    "\n",
    "As said before, the MCD64 products downloaded here contain the entire contiguous United States, and we are only interested in the state of Montana. Firstly, we will `clip` the burn area files to the state of Montana so that no unnecessary computations are done.\n",
    "\n",
    "Run the below cell block to clip the burn area shapefiles to the state of Montana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprojected and clipped year 2000\n",
      "Reprojected and clipped year 2001\n",
      "Reprojected and clipped year 2002\n",
      "Reprojected and clipped year 2003\n",
      "Reprojected and clipped year 2004\n",
      "Reprojected and clipped year 2005\n",
      "Reprojected and clipped year 2006\n",
      "Reprojected and clipped year 2007\n",
      "Reprojected and clipped year 2008\n",
      "Reprojected and clipped year 2009\n",
      "Reprojected and clipped year 2010\n",
      "Reprojected and clipped year 2011\n",
      "Reprojected and clipped year 2012\n",
      "Reprojected and clipped year 2013\n",
      "Reprojected and clipped year 2014\n",
      "Reprojected and clipped year 2015\n",
      "Reprojected and clipped year 2016\n",
      "Reprojected and clipped year 2017\n",
      "Reprojected and clipped year 2018\n",
      "Reprojected and clipped year 2019\n",
      "Reprojected and clipped year 2020\n",
      "All input shapefiles clipped!\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import warnings\n",
    "\n",
    "# Read the state boundary shapefile and determine its CRS\n",
    "state_shp_folder = \"montana_shp\"\n",
    "state_gdf = gpd.read_file(state_shp_folder)\n",
    "state_crs = state_gdf.crs\n",
    "\n",
    "# Sometimes shapefiles are empty from no wildfires. Ignore these warnings.\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Order the years ascending, and exclude any system files\n",
    "sorted_year_folders = sorted([folder for folder in os.listdir(burn_area_folder) if folder.isdigit()], key=int)\n",
    "\n",
    "# Iterate through each subfolder in the directory\n",
    "for year_folder in sorted_year_folders:\n",
    "    year_folder_path = os.path.join(burn_area_folder, year_folder)\n",
    "    \n",
    "    # Check if it's a directory and matches the year pattern (e.g., 2000, 2001, etc.)\n",
    "    if os.path.isdir(year_folder_path) and year_folder.isdigit():\n",
    "        # Iterate through each file in the year subfolder\n",
    "        for filename in os.listdir(year_folder_path):\n",
    "            file_path = os.path.join(year_folder_path, filename)\n",
    "            \n",
    "            # Check if the file is a shapefile (excluding the associated .shx, .dbf, etc. files)\n",
    "            if filename.endswith('.shp'):\n",
    "                # Read the shapefile\n",
    "                gdf = gpd.read_file(file_path)\n",
    "                \n",
    "                # Reproject the shapefile to match the Montana shapefile's CRS\n",
    "                gdf = gdf.to_crs(state_crs)\n",
    "                \n",
    "                # Clip the shapefile using the Montana shapefile\n",
    "                clipped_gdf = gpd.clip(gdf, state_gdf)\n",
    "                \n",
    "                # Save the clipped shapefile\n",
    "                clipped_file_path = os.path.join(year_folder_path, f\"clipped_{filename}\")\n",
    "                clipped_gdf.to_file(clipped_file_path)\n",
    "\n",
    "        print(f\"Reprojected and clipped year {year_folder}\")\n",
    "\n",
    "print(\"All input shapefiles clipped!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above code did not modify the original shapefiles, in case they are needed later. They are saved within the same folder structure as prior, just with the prefix `clipped_` to distinguish them from the downloaded files.\n",
    "\n",
    "Now all of the touching geometries for each \"blob\" must be dissolved. As each file represents a calendar month (numbered by julian day), we need to dissolve all touching geometries because we can estimate (with slight confidence) that each \"blob\" is a single fire event. \n",
    "\n",
    "If the blob consists of a dozen individual shapes, we do not want to claim the area had twelve fires for the month. Individual, non-touching geometries are not modified.\n",
    "\n",
    "This process below is more involved than a standard \"dissolve\" as we do not just want **all** geometries to merge into one. In any instance where there are burn areas separated geographically, this oversight would make the data unusable for counting and accurate area measurements. Instead, we need to make a temporary attribute called `temp` and assign it to all geometries in the shapefile. Then we will find all touching geometries and dissolve just those.\n",
    "\n",
    "Run the below code to dissolve all touching geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2000 dissolved.\n",
      "Year 2001 dissolved.\n",
      "Year 2002 dissolved.\n",
      "Year 2003 dissolved.\n",
      "Year 2004 dissolved.\n",
      "Year 2005 dissolved.\n",
      "Year 2006 dissolved.\n",
      "Year 2007 dissolved.\n",
      "Year 2008 dissolved.\n",
      "Year 2009 dissolved.\n",
      "Year 2010 dissolved.\n",
      "Year 2011 dissolved.\n",
      "Year 2012 dissolved.\n",
      "Year 2013 dissolved.\n",
      "Year 2014 dissolved.\n",
      "Year 2015 dissolved.\n",
      "Year 2016 dissolved.\n",
      "Year 2017 dissolved.\n",
      "Year 2018 dissolved.\n",
      "Year 2019 dissolved.\n",
      "Year 2020 dissolved.\n",
      "All shapefiles dissolved!\n"
     ]
    }
   ],
   "source": [
    "# Order the years ascending, and exclude any system files\n",
    "sorted_year_folders = sorted([folder for folder in os.listdir(burn_area_folder) if folder.isdigit()], key=int)\n",
    "\n",
    "# Iterate through each subfolder in the directory\n",
    "for year_folder in sorted_year_folders:\n",
    "    year_folder_path = os.path.join(burn_area_folder, year_folder)\n",
    "    \n",
    "    # Check if it's a directory and matches the year pattern (e.g., 2000, 2001, etc.)\n",
    "    if os.path.isdir(year_folder_path) and year_folder.isdigit():\n",
    "        # Iterate through each file in the year subfolder\n",
    "        for filename in os.listdir(year_folder_path):\n",
    "            file_path = os.path.join(year_folder_path, filename)\n",
    "            \n",
    "            # Check if the file is a \"clipped_\" shapefile (excluding the associated .shx, .dbf, etc. files)\n",
    "            if filename.startswith('clipped_') and filename.endswith('.shp'):\n",
    "                # Read the shapefile using geopandas\n",
    "                gdf = gpd.read_file(file_path)\n",
    "                \n",
    "                # Create a temporary attribute and set its value to a constant\n",
    "                gdf['temp'] = 1\n",
    "                \n",
    "                # Dissolve using the temporary attribute\n",
    "                dissolved_gdf = gdf.dissolve(by='temp')\n",
    "\n",
    "                # Reset the index of the dissolved GeoDataFrame\n",
    "                dissolved_gdf = dissolved_gdf.reset_index(drop=True)\n",
    "\n",
    "                \n",
    "                # Define the output path for the dissolved shapefile\n",
    "                dissolved_file_path = os.path.join(year_folder_path, filename.replace(\"clipped_\", \"dissolved_\"))\n",
    "                \n",
    "                # Save the dissolved shapefile\n",
    "                dissolved_gdf.to_file(dissolved_file_path)\n",
    "\n",
    "        print(f\"Year {year_folder} dissolved.\")\n",
    "\n",
    "print(\"All shapefiles dissolved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the burn area data has been clipped and dissolved, it needs to be merged to form a complete [\"fire season\"](https://www.fs.usda.gov/fs-tags/fire-season). In conversation with Dr. Giglio, Montana has been described as essentially having the same fire season as the calendar year, so all dissolved shapefiles for the given year will now be combined into one shapefile. This is the last step before insights can be gathered on the data.\n",
    "\n",
    "Run the below code block to merge all monthly shapefiles into yearly shapefiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged year 2000.\n",
      "Merged year 2001.\n",
      "Merged year 2002.\n",
      "Merged year 2003.\n",
      "Merged year 2004.\n",
      "Merged year 2005.\n",
      "Merged year 2006.\n",
      "Merged year 2007.\n",
      "Merged year 2008.\n",
      "Merged year 2009.\n",
      "Merged year 2010.\n",
      "Merged year 2011.\n",
      "Merged year 2012.\n",
      "Merged year 2013.\n",
      "Merged year 2014.\n",
      "Merged year 2015.\n",
      "Merged year 2016.\n",
      "Merged year 2017.\n",
      "Merged year 2018.\n",
      "Merged year 2019.\n",
      "Merged year 2020.\n",
      "Merged all monthly shapefiles into yearly shapefiles.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Order the years ascending, and exclude any system files\n",
    "sorted_year_folders = sorted([folder for folder in os.listdir(burn_area_folder) if folder.isdigit()], key=int)\n",
    "\n",
    "# Sometimes shapefiles are empty from no wildfires. Ignore these warnings.\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Iterate through each subfolder in the directory\n",
    "for year_folder in sorted_year_folders:\n",
    "    year_folder_path = os.path.join(burn_area_folder, year_folder)\n",
    "    \n",
    "    # Check if it's a directory and matches the year pattern (e.g., 2000, 2001, etc.)\n",
    "    if os.path.isdir(year_folder_path) and year_folder.isdigit():\n",
    "        # List to store the GeoDataFrames from each \"dissolved_\" shapefile\n",
    "        gdf_list = []\n",
    "        \n",
    "        # Iterate through each file in the year subfolder\n",
    "        for filename in os.listdir(year_folder_path):\n",
    "            file_path = os.path.join(year_folder_path, filename)\n",
    "            \n",
    "            # Check if the file is a \"dissolved_\" shapefile (excluding the associated .shx, .dbf, etc. files)\n",
    "            if filename.startswith('dissolved_') and filename.endswith('.shp'):\n",
    "                # Read the shapefile using geopandas\n",
    "                gdf = gpd.read_file(file_path)\n",
    "                \n",
    "                # Append the GeoDataFrame to the list\n",
    "                gdf_list.append(gdf)\n",
    "        \n",
    "        # Merge all the GeoDataFrames in the list\n",
    "        merged_gdf = pd.concat(gdf_list, ignore_index=True)\n",
    "        \n",
    "        # Define the output path for the yearly shapefile\n",
    "        yearly_file_path = os.path.join(year_folder_path, f\"{year_folder}_yearly.shp\")\n",
    "        \n",
    "        # Save the merged GeoDataFrame as a yearly shapefile\n",
    "        merged_gdf.to_file(yearly_file_path)\n",
    "\n",
    "    print(f\"Merged year {year_folder}.\")\n",
    "\n",
    "print(\"Merged all monthly shapefiles into yearly shapefiles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can derive metrics from the data! The Montana shapefile contains county-level boundaries and their names, so we can use this to determine how many wildfire events each county has each year, the total area of wildfire burns in each county, and the percentage of total land in the county that has burned.\n",
    "\n",
    "To do this, we first need to convert the Montana shapefile and yearly burn area shapefiles from the degree-based Coordinate Reference System into a meter-based CRS so we can calculate area accurately.\n",
    "\n",
    "To recreate the data format used in Dr. Silva's regression algorithm, we will store the output as a table, sorted first by the ascending year of the data, then we sort by county name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>AREA_KM^2</th>\n",
       "      <th>PERCENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beaverhead</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Horn</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blaine</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Broadwater</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carbon</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>Treasure</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>666.086659</td>\n",
       "      <td>26.419181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Valley</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>784.388145</td>\n",
       "      <td>5.963542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>Wheatland</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>67.218629</td>\n",
       "      <td>1.816731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Wibaux</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>Yellowstone</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>67.218629</td>\n",
       "      <td>0.976194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             NAME  YEAR COUNT   AREA_KM^2    PERCENT\n",
       "0      Beaverhead  2000     0           0          0\n",
       "1        Big Horn  2000     0           0          0\n",
       "2          Blaine  2000     0           0          0\n",
       "3      Broadwater  2000     0           0          0\n",
       "4          Carbon  2000     0           0          0\n",
       "...           ...   ...   ...         ...        ...\n",
       "1171     Treasure  2020     1  666.086659  26.419181\n",
       "1172       Valley  2020     3  784.388145   5.963542\n",
       "1173    Wheatland  2020     1   67.218629   1.816731\n",
       "1174       Wibaux  2020     0         0.0        0.0\n",
       "1175  Yellowstone  2020     1   67.218629   0.976194\n",
       "\n",
       "[1176 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the CRS to a local one suitable for area calculations (e.g., UTM Zone 12N for Montana)\n",
    "local_crs = \"EPSG:32612\"  # UTM Zone 12N\n",
    "state_gdf = state_gdf.to_crs(local_crs)\n",
    "\n",
    "# Create an empty main dataframe to store the results\n",
    "main_df = pd.DataFrame(columns=[\"NAME\", \"YEAR\", \"COUNT\", \"AREA_KM^2\", \"PERCENT\"])\n",
    "\n",
    "# Order the years ascending, and exclude any system files\n",
    "sorted_year_folders = sorted([folder for folder in os.listdir(burn_area_folder) if folder.isdigit()], key=int)\n",
    "\n",
    "# Iterate through each subfolder in the directory\n",
    "for year_folder in sorted_year_folders:\n",
    "    year_folder_path = os.path.join(burn_area_folder, year_folder)\n",
    "    \n",
    "    # Check if it's a directory and matches the year pattern (e.g., 2000, 2001, etc.)\n",
    "    if os.path.isdir(year_folder_path) and year_folder.isdigit():\n",
    "        yearly_file_path = os.path.join(year_folder_path, f\"{year_folder}_yearly.shp\")\n",
    "        \n",
    "        if os.path.exists(yearly_file_path):\n",
    "            # Read the yearly shapefile\n",
    "            yearly_gdf = gpd.read_file(yearly_file_path).to_crs(local_crs)\n",
    "\n",
    "            # If the GeoDataFrame is empty, append zeros for that year and continue to the next iteration\n",
    "            if yearly_gdf.empty:\n",
    "                year_df = pd.DataFrame({\n",
    "                    \"NAME\": state_gdf[\"NAME\"],\n",
    "                    \"YEAR\": year_folder,\n",
    "                    \"COUNT\": [0] * len(state_gdf),\n",
    "                    \"AREA_KM^2\": [0] * len(state_gdf),\n",
    "                    \"PERCENT\": [0] * len(state_gdf)\n",
    "                })\n",
    "                main_df = pd.concat([main_df, year_df], ignore_index=True)\n",
    "                continue\n",
    "\n",
    "            # Perform a spatial join between the yearly shapefile and the Montana shapefile\n",
    "            joined_gdf = gpd.sjoin(yearly_gdf, state_gdf[['geometry', 'NAME']], how=\"inner\", predicate=\"intersects\")\n",
    "            \n",
    "            # Group by the county name and calculate the required metrics\n",
    "            grouped = joined_gdf.groupby(\"NAME\")\n",
    "            count = grouped.size()\n",
    "            area = grouped.geometry.apply(lambda x: x.unary_union.area).divide(1e6)  # Convert from m^2 to km^2\n",
    "            \n",
    "            # Get the area of each county\n",
    "            county_area = state_gdf.set_index(\"NAME\").geometry.area.divide(1e6)  # Convert from m^2 to km^2\n",
    "            \n",
    "            # Calculate the percentage of the burned area for each county\n",
    "            percent = area.divide(county_area).multiply(100)\n",
    "            \n",
    "            # Default DataFrame for all counties\n",
    "            default_data = {\n",
    "                \"NAME\": state_gdf[\"NAME\"],\n",
    "                \"YEAR\": year_folder,\n",
    "                \"COUNT\": [0] * len(state_gdf),\n",
    "                \"AREA_KM^2\": [0] * len(state_gdf),\n",
    "                \"PERCENT\": [0] * len(state_gdf)\n",
    "            }\n",
    "            year_df = pd.DataFrame(default_data)\n",
    "\n",
    "            # Update the DataFrame with actual values for counties that had wildfires\n",
    "            for county in count.index:\n",
    "                year_df.loc[year_df[\"NAME\"] == county, \"COUNT\"] = count[county]\n",
    "                year_df.loc[year_df[\"NAME\"] == county, \"AREA_KM^2\"] = area[county]\n",
    "                year_df.loc[year_df[\"NAME\"] == county, \"PERCENT\"] = percent[county]\n",
    "\n",
    "        # Append this year's results to the main dataframe\n",
    "        main_df = pd.concat([main_df, year_df], ignore_index=True)\n",
    "\n",
    "# Sort the main dataframe by year and then by county name\n",
    "main_df = main_df.sort_values(by=[\"YEAR\", \"NAME\"]).reset_index(drop=True)\n",
    "\n",
    "# Display results to user:\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "main_df.to_csv('burnarea.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
